version: '3'

services:
  #spark-master:
  #  image: bde2020/spark-master:3.0.0-hadoop3.2
  #  container_name: spark-master
  #  ports:
  #    - "9090:8080"
  #    - "7077:7077"
  #  environment:
  #    - INIT_DAEMON_STEP=setup_spark
  #    - CORE_CONF_fs_defaultFS=hdfs://namenode:9000 #It shows where the namenode lies.
  #  networks:
  #    big-data-net:
  #      ipv4_address: 10.0.0.20
  #  cap_add: #Enabling the container to manage the networking.
  #    - NET_ADMIN
  #  volumes: #Maps the container folder on the right to local folder on the left.
  #    - ${path}/scripts:/home
  #    - ${path}/conf:/spark/conf/

  #spark-worker-1:
  #  image: bde2020/spark-worker:3.0.0-hadoop3.2
  #  container_name: spark-worker-1
  #  depends_on:
  #    - spark-master
  #  ports:
  #    - "8081:8081"
  #  environment:
  #    - "SPARK_MASTER=spark://spark-master:7077"
  #    - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
  #    - 'SPARK_MODE: worker'
  #    - 'SPARK_WORKER_CORES: 4'
  #    - 'SPARK_WORKER_MEMORY: 6G'
  #  networks:
  #    big-data-net:
  #      ipv4_address: 10.0.0.21
  #  cap_add: #Enabling the container to manage the networking.
  #    - NET_ADMIN    
      
 
  #jupyter:
  #  container_name: jupyter
  #  image: "jupyter/all-spark-notebook"
  #  volumes: #Maps the jupyter container folder on the right to local folder on the left.
  #    - ${path}/jupyter:/home/jovyan/work
  #  ports:
  #    - 8888:8888
  #  networks:
  #    big-data-net:
  #      ipv4_address: 10.0.0.23
  #  cap_add:
  #    - NET_ADMIN
  #  env_file:
  #    - stack.env
  #  environment: # enables a sudo privilages in the container
  #    - GRANT_SUDO=yes
  #  command: /bin/sh -c  "start-notebook.sh --user root --NotebookApp.token=''" # enables a sudo privilages in the container


  #jupyter_notebook:
  #  image: jupyter/minimal-notebook
  #  volumes: #Maps the jupyter container folder on the right to local folder on the left.
  #    - ${path}/jupyter:/home/jovyan/work
  #  ports:
  #    - 8889:8888
  #  container_name: jupyter_notebook
  #  networks:
  #    big-data-net:
  #      ipv4_address: 10.0.0.24
  #  cap_add:
  #    - NET_ADMIN
  #  env_file:
  #    - stack.env
  #  environment: # enables a sudo privilages in the container
  #    - GRANT_SUDO=yes
  #  command: /bin/sh -c  "start-notebook.sh --user root --NotebookApp.token=''" # enables a sudo privilages in the container
    
  spark-master-test:
    image: docker.io/bitnami/spark:3.2
    container_name: spark-master-test
    ports:
      - "8082:8080"
      - "7078:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    networks:
      big-data-net:
        ipv4_address: 10.0.0.25
    cap_add: #Enabling the container to manage the networking.
      - NET_ADMIN
    volumes: #Maps the container folder on the right to local folder on the left.
      - ${path}/scripts-test:/home
      - ${path}/conf-test:/spark/conf/
      
  spark-worker-test:
    image: docker.io/bitnami/spark:3.2
    container_name: spark-worker-test
    depends_on:
      - spark-master-test
    ports:
      - "8083:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master-test:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=4
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    networks:
      big-data-net:
        ipv4_address: 10.0.0.26
    cap_add: #Enabling the container to manage the networking.
      - NET_ADMIN 
      
networks:
  big-data-net:
    name: big-data-net
    driver: bridge
    ipam:
      config:
        - subnet: 10.0.0.0/16
    external: true

