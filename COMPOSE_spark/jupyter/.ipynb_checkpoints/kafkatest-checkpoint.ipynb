{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b7cba4-d1a0-48b1-bc21-625ba199cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef44c18c-910f-448d-9a26-e15b1bfd9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"test\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dee418e-04d8-4a66-a937-f946e10b0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"10.0.0.10:9092\") \\\n",
    "    .option(\"subscribe\", \"crypto_rates\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4c7b0f-a064-4845-ac09-f12ef7a598a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, LongType\n",
    "\n",
    "# Define the schema for JSON messages\n",
    "schema = StructType() \\\n",
    "    .add(\"id\", StringType()) \\\n",
    "    .add(\"symbol\", StringType()) \\\n",
    "    .add(\"currencySymbol\", StringType()) \\\n",
    "    .add(\"type\", StringType()) \\\n",
    "    .add(\"rateUsd\", DoubleType()) \\\n",
    "    .add(\"timestamp\", LongType())\n",
    "\n",
    "# Parse JSON messages from Kafka topic\n",
    "parsed_df = streaming_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(\"value\", schema).alias(\"data\")).select(\"data.*\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba95bf91-8db5-4600-97c0-b5bda1222c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = parsed_df  \\\n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"output_parquet\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint_dir_output_parquet\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97e3cb-26e9-4b8a-ad17-195a8b20092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, LongType\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaReader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the schema to parse the JSON data from Kafka\n",
    "schema = StructType() \\\n",
    "    .add(\"id\", StringType()) \\\n",
    "    .add(\"symbol\", StringType()) \\\n",
    "    .add(\"currencySymbol\", StringType()) \\\n",
    "    .add(\"type\", StringType()) \\\n",
    "    .add(\"rateUsd\", DoubleType()) \\\n",
    "    .add(\"timestamp\", LongType())\n",
    "\n",
    "# Define the Kafka parameters\n",
    "kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": \"10.0.0.10:9092\",\n",
    "    \"subscribe\": \"crypto_rates\"\n",
    "}\n",
    "# \n",
    "# Read data from Kafka using the defined schema\n",
    "kafka_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"10.0.0.10:9092\") \\\n",
    "    .option(\"subscribe\", \"crypto_rates\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .load() \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(\"value\", schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "query = kafka_df.writeStream \\\n",
    "    .format(\"json\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"path\", \"output_json\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint_json\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
